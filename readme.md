# FantasyIDiap ICCV25 Challenge - Image DeepFake Detection and Binary Classification 

This repository contained a complete pipeline for the **FantasyIDiap ICCV25 Challenge**, which focused on distinguishing between **bonafide** (genuine) and **attack** (forged) identity card images. The project utilized multiple deep learning models, including **ResNet18**, **ResNet50**, and **Swin Transformers**, to address the critical issue of identity document forgery in various digital applications.

---

## ğŸ“Œ Problem Statement

In the modern digital landscape, identity cards served essential purposes such as **KYC verifications**, **financial onboarding**, and **authentication**. However, **identity card forgery** emerged as a widespread fraudulent practice, involving manipulation of elements such as **ID numbers**, **names**, **dates of birth**, and **photographs**.

This project aimed to develop an **AI-based model** that automatically classified identity documents as **genuine or fake** by analyzing their **visual features** and **structural patterns**. The challenge was addressed using the **FantasyID Dataset**, a **synthetic yet realistic** dataset specifically designed for forgery detection.

---

## ğŸ“‚ Dataset Overview

**Classes of Images:**

* **bonafide**: Genuine ID cards
* **digital\_1**: Digitally forged copies (attack type 1)
* **digital\_2**: Digitally forged copies with alternate transformations (attack type 2)

**Multiple Device Captures:**

* Huawei
* iPhone 15 Pro
* Scanner

---

### ğŸ“ Dataset Structure

```
FantasyIDiap-ICCV25-Challenge/
â”œâ”€â”€ attack/
â”‚   â”œâ”€â”€ digital_1/
â”‚   â”‚   â”œâ”€â”€ huawei/
â”‚   â”‚   â”œâ”€â”€ iphone15pro/
â”‚   â”‚   â””â”€â”€ scan/
â”‚   â””â”€â”€ digital_2/
â”‚       â”œâ”€â”€ huawei/
â”‚       â”œâ”€â”€ iphone15pro/
â”‚       â””â”€â”€ scan/
â”œâ”€â”€ bonafide/
â”‚   â”œâ”€â”€ huawei/
â”‚   â”œâ”€â”€ iphone15pro/
â”‚   â””â”€â”€ scan/
â”œâ”€â”€ fantasyIDiap-train.csv
â”œâ”€â”€ fantasyIDiap-test.csv
â”œâ”€â”€ fantasyIDiap-oneset.csv
```

---

## ğŸ“Š Dataset Characteristics

* **Training Set**: 1,899 images (633 bonafide, 1,266 attacks)
* **Test Set**: 459 images (153 bonafide, 306 attacks)
* Maintained an approximate **2:1 attack-to-bonafide ratio**
* Contained rich metadata fields: `path`, `label`, `device`, `attack_type`, `split`, `relative_path`

---

## âš™ï¸ Installation

Ran in the provided notebook:

```bash
pip install opencv-python seaborn tqdm torch torchvision torchaudio timm
```

---

## â–¶ï¸ Running the Notebook

1. Cloned the repository or downloaded the `.ipynb` file.
2. Set the dataset path:

```python
DATASET_PATH = "/path/to/FantasyIDiap-ICCV25-Challenge"
```

3. Uncommented a model:

* **ResNet18**
* **ResNet50**
* **Swin Transformer**

4. Executed the notebook cell-by-cell in **Jupyter**, **VSCode**, or **Google Colab**.

---

## ğŸš€ Features

* Performed visual inspection of images
* Prepared and analyzed metadata
* Conducted data integrity checks
* Set up **PyTorch Datasets & Dataloaders**
* Supported multiple model options (**ResNet18**, **ResNet50**, **Swin Transformer**)
* Trained models per device & per attack type
* Generated accuracy metrics, confusion matrices, and performance logs

---

## ğŸ§ª Methodology

### **General Data Preprocessing & Augmentation**

* Resized images to **224Ã—224**
* Applied random horizontal flip (p=0.5)
* Added color jittering
* Used random affine transformations
* Normalized images to `[-1, 1]`
* Employed **WeightedRandomSampler** for class balance

---

### **Model-Specific Training**

#### **ResNet18**

* Utilized a pre-trained ImageNet model
* Replaced final layer with: Dropout(0.4) â†’ Linear(512â†’2)
* Fine-tuned entire backbone after initial freezing
* Optimizer: Adam (`lr=1e-4`)
* Loss: CrossEntropyLoss

#### **ResNet50**

* Unfroze `layer4` + classifier head
* Custom head: BatchNorm â†’ Dropout(0.5) â†’ Linear(256) â†’ ReLU â†’ BatchNorm â†’ Dropout(0.5) â†’ Linear(2)
* Optimizer: AdamW (`lr=1e-4`)
* Loss: CrossEntropyLoss (weighted)
* Trained for 17 epochs

#### **Swin Transformer**

* Used Tiny variant pre-trained with `Swin_T_Weights.DEFAULT`
* Replaced head with Linear(in\_featuresâ†’2)
* Trained last 40% of backbone
* Loss: Label Smoothing Cross-Entropy (`smoothing=0.1`)
* Scheduler: CosineAnnealingLR (10 epochs)

---

## ğŸ“Š Evaluation Strategy & Metrics

* Evaluated 12 trained model combinations on **6 custom test configurations**
* **Metrics**: Accuracy, AUC, Confusion Matrix
* **Visualizations**:

  * Accuracy heatmaps
  * ROC curves
  * Grad-CAM visualizations
  * Diagnostic plots
  * Boxplots & bar charts for devices & attack types

---

## ğŸ“Š Results

* **Highlights**:

  * Heatmaps revealed cross-device & cross-attack generalization
  * Confusion matrices showed misclassification patterns
  * Grad-CAM visualizations highlighted focus areas
  * Boxplots identified hardest device/attack combinations

---

## ğŸ”„ Re-Evaluation

Reloaded saved models & switched architectures for benchmarking.

---

## âœ… Built-in Checks

* Validated image loading
* Raised errors for missing labels
* Skipped empty batches
* Handled empty splits
* Fixed `get_predictions()` typo
* Ensured reproducibility with `set_seed()`

---

## ğŸ“¦ Requirements

* Python â‰¥ 3.7
* PyTorch â‰¥ 1.12
* torchvision
* timm
* tqdm
* OpenCV
* matplotlib
* seaborn
* pandas
* numpy

---

## ğŸ“¬ Questions?

Opened an issue or contacted the maintainers.
**Enjoyed experimenting with CNNs and Transformers! ğŸ¤–**
